# From https://github.com/lightvector/KataGo/blob/9c79faaf299a37af38982181fdfec2a642d50d9b/cpp/configs/match_example.cfg
# Example config for C++ match runner
# This is an example template config for the "match" subcommand of KataGo. e.g:
# ./engines/KataGo-raw/cpp/katago match \
# -config configs/test/match_test_1.cfg \
# -log-file match_logs/match1.log \
# -sgf-output-dir match_sgfs/
# On a good GPU, the match subcommand enables testing of KataGo nets against each other
# or a net against itself with different parameters vastly faster than anything
# else, because multiple games can share GPU batching.
#
# Beware however of using this to test differing numbers of threads or test time-based search limits.
# Because many games will be run simultaneously, they will compete from each other for compute power,
# and although the total will run much faster than if you had run them one by one, you might also get
# substantially different results not reflective of the strength of a configuration when run in a real
# match setting, on a machine by itself. For fixed numbers of visits or playouts instead of fixed time,
# and with numSearchThreads = 1, there should be no problem though, because then the compute time has
# no influence on the result of the computation.
#
# See gtp config for descriptions of most of these params.
#
# For almost any parameter in this config that is related to a bot, rather than to the match as a whole
# (so, visits, search parameters, model files, etc. but NOT the rules, max games, log info, etc)
# you can specify them differentially between different bots by appending the index of the bot.
# For example, if you were testing different numbers of visits, you could try:
#
# numBots = 3
# botName0 = lowVisits
# botName1 = midVisits
# botName2 = highVisits
#
# maxVisits0 = 100
# maxVisits1 = 300
# maxVisits2 = 1000
#
# Or, if you were testing different neural nets, with different search configurations, you could do:
#
# nnModelFile0 = path/to/first/model/file.bin.gz
# nnModelFile1 = path/to/second/model/file.bin.gz
#
# And specify different search parameters for them if you wanted:
# cpuctExploration0 = 1.5
# cpuctExploration1 = 1.3

# Logs------------------------------------------------------------------------------------

logSearchInfo = false
logMoves = false
logGamesEvery = 50
logToStdout = true

# Bots-------------------------------------------------------------------------------------
# For multiple bots, you can specify their names as botName0,botName1, etc.
# If the bots are using different models, specify nnModelFile0, nnModelFile1, etc.

numBots=4
botName0 = b6-bad
botName1 = b10-pro
botName2 = b15-super
botName3 = b40-god
nnModelFile0 = models/kata1-b6c96-s175395328-d26788732.txt.gz
nnModelFile1 = models/kata1-b10c128-s197428736-d67404019.txt.gz
nnModelFile2 = models/kata1-b15c192-s497233664-d149638345.txt.gz
nnModelFile3 = models/kata1-b40c256-s10359230464-d2525387336.bin.gz

# These bots will not play each other, but will still be opponents for other bots
# secondaryBots = 0,1,3
# Only these bots will actually play games. Useful if you have a config file with many more
# bots defined but you want to only selectively enable a few.
#includeBots = 0,1,2,3


# Match-----------------------------------------------------------------------------------
numGameThreads=4 # How many games to run in parallel at a time?

numGamesTotal=4
maxMovesPerGame=1200

allowResignation = true
resignThreshold = -0.95
resignConsecTurns = 6

# Rules------------------------------------------------------------------------------------
# See https://lightvector.github.io/KataGo/rules.html for a description of the rules.

# We use Tromp-Taylor rules
koRules = POSITIONAL
scoringRules = AREA
taxRules = NONE
multiStoneSuicideLegals = true
hasButtons = false

bSizes = 19
bSizeRelProbs = 100

komiAuto = True   # Automatically adjust komi to what the neural nets think are fair
# komiMean = 7.5  # Specify explicit komi
# policyInitAreaProp = 0
# compensateAfterPolicyInitProb = 1.0  # Additionally make komi fair this often after the high-temperature moves.
# policyInitAreaTemperature = 1
handicapProb = 0.0
handicapCompensateKomiProb = 1.0
# numExtraBlackFixed = 3  # When playing handicap games, always use exactly this many extra black moves

# Search limits-----------------------------------------------------------------------------------

maxVisits = 1200  # To match https://github.com/lightvector/KataGo/blob/master/TrainingHistory.md
# maxPlayouts = 300
# maxTime = 60

numSearchThreads = 8

# GPU Settings-------------------------------------------------------------------------------

nnMaxBatchSize = 32
nnCacheSizePowerOfTwo = 21
nnMutexPoolSizePowerOfTwo = 17
nnRandomize = true


# How many threads should there be to feed positions to the neural net?
# Server threads are indexed 0,1,...(n-1) for the purposes of the below GPU settings arguments
# that specify which threads should use which GPUs.
# NOTE: This parameter is probably ONLY useful if you have multiple GPUs, since each GPU will need a thread.
# If you're tuning single-GPU performance, use numSearchThreads instead.
numNNServerThreadsPerModel = 1


# TENSORRT GPU settings--------------------------------------
# These only apply when using the TENSORRT version of KataGo.

# IF USING ONE GPU: optionally uncomment and change this if the GPU you want to use turns out to be not device 0
# trtDeviceToUse = 0

# IF USING TWO GPUS: Uncomment these two lines (AND set numNNServerThreadsPerModel above):
# trtDeviceToUseThread0 = 0  # change this if the first GPU you want to use turns out to be not device 0
# trtDeviceToUseThread1 = 1  # change this if the second GPU you want to use turns out to be not device 1

# IF USING THREE GPUS: Uncomment these three lines (AND set numNNServerThreadsPerModel above):
# trtDeviceToUseThread0 = 0  # change this if the first GPU you want to use turns out to be not device 0
# trtDeviceToUseThread1 = 1  # change this if the second GPU you want to use turns out to be not device 1
# trtDeviceToUseThread2 = 2  # change this if the third GPU you want to use turns out to be not device 2

# You can probably guess the pattern if you have four, five, etc. GPUs.


# CUDA GPU settings--------------------------------------
# For the below, "model" refers to a neural net, from the nnModelFile parameter(s) above.
cudaGpuToUse = 0 #use gpu 0 for all server threads (numNNServerThreadsPerModel) unless otherwise specified per-model or per-thread-per-model
# cudaGpuToUseModel0 = 3 #use gpu 3 for model 0 for all threads unless otherwise specified per-thread for this model
# cudaGpuToUseModel1 = 2 #use gpu 2 for model 1 for all threads unless otherwise specified per-thread for this model
# cudaGpuToUseModel0Thread0 = 3 #use gpu 3 for model 0, server thread 0
# cudaGpuToUseModel0Thread1 = 2 #use gpu 2 for model 0, server thread 1

# cudaUseFP16 = auto
# cudaUseNHWC = auto


# OpenCL GPU settings--------------------------------------
# These only apply when using OpenCL as the backend for inference.
# (For GTP, we only ever have one model, when playing matches, we might have more than one, see match_example.cfg)

# Default behavior is just to always use gpu 0, you will want to uncomment and adjust one or more of these lines
# to take advantage of a multi-gpu machine
# openclGpuToUse = 0 #use gpu 0 for all server threads (numNNServerThreadsPerModel) unless otherwise specified per-model or per-thread-per-model
# openclGpuToUseModel0 = 3 #use gpu 3 for model 0 for all threads unless otherwise specified per-thread for this model
# openclGpuToUseModel1 = 2 #use gpu 2 for model 1 for all threads unless otherwise specified per-thread for this model
# openclGpuToUseModel0Thread0 = 3 #use gpu 3 for model 0, server thread 0
# openclGpuToUseModel0Thread1 = 2 #use gpu 2 for model 0, server thread 1

# Uncomment to tune OpenCL for every board size separately, rather than only the largest possible size
# openclReTunePerBoardSize = true

# openclUseFP16 = auto


# Eigen-specific settings--------------------------------------
# These only apply when using the Eigen (pure CPU) version of KataGo.

# This is the number of CPU threads for evaluating the neural net on the Eigen backend.
# It defaults to numSearchThreads.
# numEigenThreadsPerModel = X


# Root move selection and biases------------------------------------------------------------------------------
# Uncomment and edit any of the below values to change them from their default.
# Values in this section can be specified per-bot as well

chosenMoveTemperatureEarly = 0.60
# chosenMoveTemperatureHalflife = 19
chosenMoveTemperature = 0.20
# chosenMoveSubtract = 0
# chosenMovePrune = 1

# rootNumSymmetriesToSample = 1

# useLcbForSelection = true
# lcbStdevs = 5.0
# minVisitPropForLCB = 0.15

# Internal params------------------------------------------------------------------------------
# Uncomment and edit any of the below values to change them from their default.
# Values in this section can be specified per-bot as well

# winLossUtilityFactor = 1.0
# staticScoreUtilityFactor = 0.10
# dynamicScoreUtilityFactor = 0.30
# dynamicScoreCenterZeroWeight = 0.20
# dynamicScoreCenterScale = 0.75
# noResultUtilityForWhite = 0.0
# drawEquivalentWinsForWhite = 0.5

# cpuctExploration = 0.9
# cpuctExplorationLog = 0.4
# fpuReductionMax = 0.2
# rootFpuReductionMax = 0.1
# valueWeightExponent = 0.5
# rootEndingBonusPoints = 0.5
# rootPruneUselessMoves = true
# subtreeValueBiasFactor = 0.35
# subtreeValueBiasWeightExponent = 0.8

# mutexPoolSize = 256
# numVirtualLossesPerThread = 1
