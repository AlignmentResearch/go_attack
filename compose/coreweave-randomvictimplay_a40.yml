# Standard KataGo self-play training with unbounded data reuse factor (depends on number of self-play workers).
# See https://github.com/lightvector/KataGo/blob/master/SelfplayTraining.md.
#
# CoreWeeave rseources:
#   - 4 V100 GPUs
#
# See https://stackoverflow.com/a/52641495/1337463 for documentation on how to
# run commands with `sh -c`.
#
# Launch command on svm (run from repo root).
# docker-compose -f compose/svm-selfplay.yml --env-file compose/svm-selfplay.env up
#
# Or with gating:
# docker-compose -f compose/svm-selfplay.yml --env-file compose/svm-selfplay.env --profile use_gating up

version: "3"

services:
  selfplay:
    image: humancompatibleai/goattack:cpp
    build:
      context: ..
      dockerfile: ./compose/cpp/Dockerfile
    volumes:
      - type: bind
        source: $HOST_OUTPUT_DIR
        target: /outputs
      - type: bind
        source: $HOST_MODEL_DIR
        target: /models
    command: >
      sh -c "
        cd /engines/KataGo-custom &&
        ./cpp/katago victimplay \
        -output-dir /outputs/selfplay \
        -models-dir /outputs/models \
        -config $SELFPLAY_CONFIG
      "
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
              driver: nvidia
              device_ids: ["0", "1", "2"]

  train:
    image: humancompatibleai/goattack:python
    build:
      context: ..
      dockerfile: ./compose/python/Dockerfile
    volumes:
      - type: bind
        source: $HOST_OUTPUT_DIR
        target: /outputs
    command: >
      sh -c "
        cd /engines/KataGo-custom/python &&
        ./selfplay/train.sh \
        /outputs/ \
        $TRAININGNAME \
        b6c96 \
        $BATCH_SIZE \
        main \
        -lr-scale 1.0 \
        -max-train-bucket-per-new-data 4
      "
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
              driver: nvidia
              device_ids: ["3"]

  shuffle-and-export:
    image: humancompatibleai/goattack:python
    build:
      context: ..
      dockerfile: ./compose/python/Dockerfile
    volumes:
      - type: bind
        source: $HOST_OUTPUT_DIR
        target: /outputs
    command: >
      sh -c "
        cd /engines/KataGo-custom/python &&
        ./selfplay/shuffle_and_export_loop.sh \
        $NAMEOFRUN \
        /outputs/ \
        $SCRATCH_DIRECTORY \
        $NUM_THREADS \
        $BATCH_SIZE \
        $USE_GATING &&
        sleep infinity
      "
    # shuffle_and_export_loop.sh disowns subprocesses and exits, which is why we
    # sleep at the end so the docker container doesn't exit.
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
              driver: nvidia
              device_ids: ["3"]

  # Not launched by default, must specify '--profile use_gating'
  gatekeeper:
    profiles:
      - use_gating
    image: humancompatibleai/goattack:cpp
    build:
      context: ..
      dockerfile: ./compose/cpp/Dockerfile
    volumes:
      - type: bind
        source: $HOST_OUTPUT_DIR
        target: /outputs
    command: >
      sh -c "
        cd /engines/KataGo-custom &&
        ./cpp/katago gatekeeper \
        -rejected-models-dir /outputs/rejectedmodels \
        -accepted-models-dir /outputs/models/ \
        -sgf-output-dir /outputs/gatekeepersgf/ \
        -test-models-dir /outputs/modelstobetested/ \
        -selfplay-dir /outputs/selfplay/ \
        -config $GATEKEEPER_CONFIG
      "
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
              driver: nvidia
              device_ids: ["3"]
